{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "#Here we are going to import all the libraries\n",
        "from typing import TypedDict , List, Optional\n",
        "from langchain_core.messages import BaseMessage\n",
        "from langgraph.graph import StateGraph, START, END\n",
        "from langchain_huggingface import HuggingFaceEndpoint, ChatHuggingFace\n",
        "import os\n",
        "from google.colab import userdata\n",
        "from sentence_transformers import SentenceTransformer\n",
        "import numpy as np\n",
        "import json"
      ],
      "metadata": {
        "id": "4J-zjzUYySLL"
      },
      "execution_count": 83,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#This is model API key\n",
        "os.environ[\"HUGGINGFACEHUB_API_TOKEN\"] = userdata.get(\"HUGGINGFACEHUB_API_TOKEN\")"
      ],
      "metadata": {
        "id": "1X-km8iKkXVW"
      },
      "execution_count": 82,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#The model we are going to use\n",
        "llm = HuggingFaceEndpoint(\n",
        "    repo_id=\"Qwen/Qwen2.5-7B-Instruct\",\n",
        "    task=\"text-generation\",\n",
        "    max_new_tokens=150,\n",
        "    do_sample=True,\n",
        "    temperature=0.2,\n",
        ")\n",
        "\n",
        "model = ChatHuggingFace(llm=llm)"
      ],
      "metadata": {
        "id": "JM4q4-ETkTwu"
      },
      "execution_count": 81,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Here is the embedding Logic\n",
        "class GameEmbeddingModel:\n",
        "    def __init__(self):\n",
        "        self.model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
        "\n",
        "    def embed_text(self, text: str) -> np.ndarray:\n",
        "        return self.model.encode(text, normalize_embeddings=True)\n",
        "\n",
        "    def embed_games(self, games: list[dict]) -> list[np.ndarray]:\n",
        "        texts = [\n",
        "            f\"{game['title']} {' '.join(game['genre'])} {game['style']}\"\n",
        "            for game in games\n",
        "        ]\n",
        "        return self.model.encode(texts, normalize_embeddings=True)"
      ],
      "metadata": {
        "id": "MjUz-yK2MsLd"
      },
      "execution_count": 80,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Loading the json file we are using as a database\n",
        "def load_games(path=\"games.json\"):\n",
        "    with open(path, \"r\") as f:\n",
        "        return json.load(f)\n",
        "\n",
        "\n",
        "#Function for Cosine Similarity\n",
        "def cosine_similarity(query_vec, game_vecs):\n",
        "    return np.dot(game_vecs, query_vec)"
      ],
      "metadata": {
        "id": "JWRcroCLNSC1"
      },
      "execution_count": 79,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Scoring and ranking functions\n",
        "def score_game(similarity : float, genre_match : float, popularity : float) -> float:\n",
        "    return ((0.6 * similarity) + (0.3 * genre_match) + (0.1 * popularity))\n",
        "\n",
        "\n",
        "def genre_match_score(game, task : str) -> float:\n",
        "    task_lower = task.lower()\n",
        "    matches = sum(1 for genre in game[\"genre\"]\n",
        "                  if genre.lower() in task_lower)\n",
        "    return matches / len(game[\"genre\"])"
      ],
      "metadata": {
        "id": "WjMEnSgAX-a1"
      },
      "execution_count": 78,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Here we have the explanations how can we do that\n",
        "EXPLAIN_PROMPT = \"\"\"\n",
        "You are an AI assistant explaining game recommendations.\n",
        "\n",
        "User request:\n",
        "{task}\n",
        "\n",
        "Recommended games:\n",
        "{games}\n",
        "\n",
        "Rules:\n",
        "- Explain each game briefly (2â€“3 lines max)\n",
        "- Focus on genre, style, and why it matches the request\n",
        "- Do NOT add new games\n",
        "- Do NOT change the order\n",
        "- Be concise and clear\n",
        "\"\"\"\n",
        "\n"
      ],
      "metadata": {
        "id": "mHedWEj8fEjV"
      },
      "execution_count": 77,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Here we are going to make the state for our langgraph\n",
        "class agentstate(TypedDict):\n",
        "      messages : List[BaseMessage]\n",
        "      task : str\n",
        "      plan : Optional[list[str]]\n",
        "      current_step : int\n",
        "      result : Optional[str]\n",
        "      decision : Optional[str]\n",
        "      attempts : int\n",
        "      error : Optional[str]"
      ],
      "metadata": {
        "id": "kL2Uxu0jUncP"
      },
      "execution_count": 76,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Here we are going to make nodes\n",
        "PLANNER_PROMPT = \"\"\"\n",
        "You are an AI planner for a game recommendation system.\n",
        "\n",
        "Your job:\n",
        "- Analyze the user request\n",
        "- Decide if game recommendation is required\n",
        "- Produce a clear, ordered plan\n",
        "\n",
        "Rules:\n",
        "- Output ONLY a numbered list of steps\n",
        "- Use clear, concise steps\n",
        "- If recommendations are needed, include steps for:\n",
        "  - finding similar games\n",
        "  - ranking games\n",
        "  - explaining recommendations\n",
        "- Do NOT execute anything\n",
        "- Do NOT explain your reasoning\n",
        "\n",
        "User request:\n",
        "{task}\n",
        "\"\"\"\n",
        "\n",
        "def planner_node(state : agentstate) -> agentstate:\n",
        "    prompt = PLANNER_PROMPT.format(task = state[\"task\"])\n",
        "    response = model.invoke(prompt)\n",
        "\n",
        "    steps = [step.strip()\n",
        "            for step in response.content.split(\"\\n\")\n",
        "            if step.strip()\n",
        "             ]\n",
        "\n",
        "    state[\"plan\"] = steps\n",
        "    state[\"current_step\"] = 0\n",
        "    state[\"decision\"] = \"execute\"\n",
        "    return state\n",
        "\n",
        "###############################################################\n",
        "embedding_model = GameEmbeddingModel()\n",
        "games = load_games()\n",
        "game_embeddings = embedding_model.embed_games(games)\n",
        "\n",
        "def executor_node(state : agentstate) -> agentstate:\n",
        "    step = state[\"plan\"][state[\"current_step\"]].lower()\n",
        "    SIMILARITY_THRESHOLD = 0.4\n",
        "\n",
        "    if \"similar\" in step or \"find\" in step:\n",
        "        query_vec = embedding_model.embed_text(state[\"task\"])\n",
        "        scores = cosine_similarity(query_vec, game_embeddings)\n",
        "        ranked = []\n",
        "        for i, sim in enumerate(scores):\n",
        "            if sim < SIMILARITY_THRESHOLD:\n",
        "                continue\n",
        "\n",
        "            game = games[i]\n",
        "            genre_score = genre_match_score(game, state[\"task\"])\n",
        "            final_score = score_game(\n",
        "                similarity = sim,\n",
        "                genre_match = genre_score,\n",
        "                popularity = game[\"popularity\"]\n",
        "            )\n",
        "\n",
        "            ranked.append((final_score, game))\n",
        "\n",
        "        ranked.sort(reverse=True, key=lambda x: x[0])\n",
        "        state[\"result\"] = [game for _, game in ranked]\n",
        "\n",
        "    state[\"current_step\"] += 1\n",
        "    return state\n",
        "\n",
        "###########################################################\n",
        "\n",
        "def validator_node(state : agentstate) -> agentstate:\n",
        "    if not state.get(\"result\"):\n",
        "        state[\"decision\"] = \"end\"\n",
        "        return state\n",
        "\n",
        "    if state[\"current_step\"] < len(state[\"plan\"]):\n",
        "        state[\"decision\"] = \"continue\"\n",
        "        return state\n",
        "\n",
        "    state[\"decision\"] = \"explain\"\n",
        "    return state\n",
        "\n",
        "\n",
        "def build_graph():\n",
        "    graph = StateGraph(agentstate)\n",
        "\n",
        "    graph.add_node(\"planner\", planner_node)\n",
        "    graph.add_node(\"executor\", executor_node)\n",
        "    graph.add_node(\"validator\", validator_node)\n",
        "    graph.add_node(\"explainer\", explainer_node)\n",
        "\n",
        "    graph.add_edge(START, \"planner\")\n",
        "    graph.add_edge(\"planner\", \"executor\")\n",
        "    graph.add_edge(\"executor\", \"validator\")\n",
        "\n",
        "    graph.add_conditional_edges(\n",
        "        \"validator\",\n",
        "        lambda state : state[\"decision\"],\n",
        "        {\n",
        "            \"continue\" : \"executor\",\n",
        "            \"explain\": \"explainer\",\n",
        "            \"end\" : END\n",
        "        }\n",
        "    )\n",
        "\n",
        "    graph.add_edge(\"explainer\", END)\n",
        "\n",
        "    return graph.compile()\n",
        "\n",
        "def explainer_node(state: agentstate) -> agentstate:\n",
        "    if not state.get(\"result\"):\n",
        "        state[\"result\"] = \"No recommendations could be generated.\"\n",
        "        return state\n",
        "\n",
        "    games = state[\"result\"]\n",
        "\n",
        "    games_text = \"\\n\".join(\n",
        "        f\"- {game['title']} ({', '.join(game['genre'])}, {game['style']})\"\n",
        "        for game in state[\"result\"]\n",
        "    )\n",
        "\n",
        "    prompt = EXPLAIN_PROMPT.format(\n",
        "        task=state[\"task\"],\n",
        "        games=games_text\n",
        "    )\n",
        "\n",
        "    response = llm.invoke(prompt)\n",
        "\n",
        "    state[\"result\"] = response.content\n",
        "\n",
        "    return state"
      ],
      "metadata": {
        "collapsed": true,
        "id": "eofdMUSYXBLH"
      },
      "execution_count": 75,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "graph = build_graph()\n",
        "\n",
        "initial_state = {\n",
        "    \"messages\" : [],\n",
        "    \"task\" : \"Recommend horror games like Resident Evil\",\n",
        "    \"plan\" : None,\n",
        "    \"current_step\" : 0,\n",
        "    \"result\" : None,\n",
        "    \"decision\" : None,\n",
        "    \"attempts\" : 0,\n",
        "    \"error\" : None\n",
        "}\n",
        "\n",
        "output = graph.invoke(initial_state)\n",
        "\n",
        "print(\"\\nFinal Recommendation:\\n\")\n",
        "print(output[\"result\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JNZKdX0VafmP",
        "outputId": "f8e08748-3663-427d-9940-450e8ff42275"
      },
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Final Recommendation:\n",
            "\n",
            "None\n"
          ]
        }
      ]
    }
  ]
}